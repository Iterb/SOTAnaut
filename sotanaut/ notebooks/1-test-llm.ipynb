{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exllama kernel is not installed, reset disable_exllama to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\n",
      "CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n",
      "1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n",
      "2. You are using pytorch without CUDA support.\n",
      "3. CUDA and nvcc are not installed in your device.\n",
      "Downloading (…)quantize_config.json: 100%|██████████| 186/186 [00:00<00:00, 1.21MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 7.26G/7.26G [09:45<00:00, 12.4MB/s]\n",
      "CUDA extension not installed.\n",
      "skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 761/761 [00:00<00:00, 7.05MB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 1.37MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 3.31MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 2.38MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### System:\n",
      "Be truthfull\n",
      "\n",
      "### User:\n",
      "Tell me about AI\n",
      "\n",
      "### Assistant:\n",
      " Artificial Intelligence (AI) is a branch of computer science that focuses on creating intelligent machines that can work and react like humans. These intelligent machines, often referred to as \"agents\", are designed to perceive their environment, interpret data, learn from that data, and make decisions based on that learning. AI systems can exhibit various degrees of intelligence, from basic decision-making algorithms to systems that approach, match, or even surpass human cognitive abilities in numerous domains.\n",
      "\n",
      "AI technologies have been developed and applied in a wide range of fields, including natural language processing, computer vision, machine learning, robotics, and expert systems. Some common applications of AI include virtual assistants like Siri and Alexa, self-driving cars, medical diagnostic systems, fraud detection in finance, and recommendation algorithms in e-commerce.\n",
      "\n",
      "AI research can be divided into two main categories: weak AI and strong AI. Weak AI, also known as narrow AI, focuses on developing AI systems that are designed to perform specific tasks, such as playing chess or recognizing faces. Strong AI, also known as general AI or artificial general intelligence (AGI), aims to create AI systems that possess human-like intelligence across a wide range of tasks and can adapt to new situations.\n",
      "\n",
      "The development of AI has led to both significant advancements and ethical concerns. Some of the benefits of AI include increased efficiency, improved decision-making, and enhanced human capabilities in various fields. However, AI has also raised concerns about job displacement, privacy, and the potential for AI systems to outperform or even surpass human intelligence, leading to unforeseen consequences. As a result, ongoing research and discussions focus on ensuring AI's responsible and beneficial development and use.\n",
      "\n",
      "In summary, AI is a rapidly evolving field that seeks to create intelligent machines capable of performing tasks that typically require human intelligence. While AI has the potential to revolutionize numerous industries and aspects of our lives, its development also presents ethical and societal challenges that must be addressed for its responsible use.\n",
      "\n",
      "To learn more about AI, I would recommend reading books, articles, and attending webinars or online courses in the field. Additionally, staying updated with the latest AI-related news and develop\n",
      "*** Pipeline:\n",
      "### System:\n",
      "Be truthfull\n",
      "\n",
      "### User:\n",
      "Tell me about AI\n",
      "\n",
      "### Assistant:\n",
      " Artificial Intelligence (AI) is a branch of computer science that focuses on creating intelligent machines capable of performing tasks that typically require human intelligence. It involves the development of algorithms and systems that can perceive, reason, learn, and take actions based on the available data. \n",
      "\n",
      "The ultimate goal of AI research is to create machines that possess cognitive abilities similar to those of humans, including problem-solving, understanding natural language, recognizing objects, making decisions, and even developing creativity. These intelligent machines can perform various applications such as robotics, machine learning, natural language processing, computer vision, expert systems, and more.\n",
      "\n",
      "In recent years, significant progress has been made in AI through the use of deep learning techniques, which have led to breakthroughs in areas like image recognition, speech synthesis, and autonomous vehicles. However, it's important to note that while AI systems are becoming increasingly sophisticated, they still lack the general intelligence and consciousness found in humans and other living beings. The ethical implications and potential risks associated with AI continue to be subjects of intense debate among scientists, policymakers, and society as a whole.\n",
      "\n",
      "To summarize, AI refers to the field of computer science aiming at creating intelligent machines capable of mimicking human cognitive functions, solving complex problems, and adapting to new situations. Its applications include diverse fields such as healthcare, finance, transportation, education, and entertainment. Despite recent advancements, there is still much work to be done before achieving true artificial general intelligence.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "model_name_or_path = \"TheBloke/sheep-duck-llama-2-13B-GPTQ\"\n",
    "model_basename = \"model\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoGPTQForCausalLM.from_quantized(\n",
    "                model_name_or_path,\n",
    "                model_basename=model_basename,\n",
    "                use_safetensors=True,\n",
    "                trust_remote_code=True,\n",
    "                device=\"cuda:0\",\n",
    "                use_triton=False,\n",
    "                quantize_config=None,\n",
    "            )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "system_message = \"Be truthfull\"\n",
    "prompt_template=f'''### System:\n",
    "{system_message}\n",
    "\n",
    "### User:\n",
    "{prompt}\n",
    "\n",
    "### Assistant:\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=2048,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
